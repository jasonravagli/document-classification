{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlvMFbA9eaHL"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozb1pju5no1E"
   },
   "source": [
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4kfsWBdnvFE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EF8nO8tCn0rV"
   },
   "source": [
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7lulcZCn3Ph"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG16\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Google Drive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth, drive\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTxETaJrkADl"
   },
   "source": [
    "Authenticate to Google Drive to access dataset folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5U4qYrxteh7r",
    "outputId": "c79918e9-9278-4b36-9a39-09bb48bf0570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "GoogleDrive(gauth)\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUJh9_GWocEn"
   },
   "source": [
    "General parameters and settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GF6nkn_poed2"
   },
   "outputs": [],
   "source": [
    "original_dataset_path = \"/content/drive/My Drive/document-classification/datasets/rvl-cdip/mini-dataset-1600-200-200.h5\"\n",
    "cnn_dataset_path = \"/content/drive/My Drive/document-classification/datasets/rvl-cdip/cnn-mini-dataset-1600-200-200.h5\"\n",
    "cnn_model_path = \"/content/drive/My Drive/document-classification/models/model.json\"\n",
    "cnn_weights_path = \"/content/drive/My Drive/document-classification/models/weights.h5\"\n",
    "cnn_weights_checkpoint_path = \"/content/drive/My Drive/document-classification/checkpoints/checkpoint_weights.h5\"\n",
    "history_stats_path = \"/content/drive/My Drive/document-classification/history/history_stats.csv\"\n",
    "\n",
    "# Flag to generate CNN dataset (set it to False if the dataset has already been generated)\n",
    "generate_dataset = False\n",
    "# False: skip training process and load the already learned weights to only evaluate the network\n",
    "train_network = True\n",
    "# True: resume the training from a checkpoint; False: start a new training\n",
    "# This flag is checked only if train_network=True\n",
    "resume_training = True\n",
    "\n",
    "# Shape of the images read from the mini-dataset\n",
    "original_img_shape = (1000, 750)\n",
    "# Shape of the images in input to the CNN\n",
    "cnn_image_shape = (500, 375)\n",
    "# Number of images classes\n",
    "n_classes = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "om7sJs4B0Ji0"
   },
   "source": [
    "Check if GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "h5zS1kXepHTe",
    "outputId": "7644bc4f-dcd7-4647-f7e1-ffc3c41d1e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6119263266125199351, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 13795399320139286188\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 2436519779849582483\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11150726272\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7102891325770624637\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "display(device_lib.list_local_devices())\n",
    "assert tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCaRLIXUrqAE"
   },
   "source": [
    "# Dataset preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w8surVL386H"
   },
   "source": [
    "**Function to generate a dataset for the CNN (VGG16) starting from the corresponding original dataset.**\n",
    "\n",
    "It reads all images from the original dataset, preprocesses them according to the CNN requirements (resize, convert to RGB) and finally saves them into the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFyJE8oQ4E0a"
   },
   "outputs": [],
   "source": [
    "def generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, dataset_name):\n",
    "  # Number of data rows to read from original file, process and write to the CNN file at the same time\n",
    "  # (To speedup read/write operations)\n",
    "  batch_size = 64\n",
    "\n",
    "  # Read datasets from the original HDF5 file\n",
    "  ds_original_imgs = hdf_original_file[dataset_name]\n",
    "  ds_original_labels = hdf_original_file[dataset_name + \"_labels\"]\n",
    "\n",
    "  n_imgs = ds_original_imgs.len()\n",
    "\n",
    "  # Create omonymous datasets into the HDF5 file for the CNN\n",
    "  ds_cnn_imgs = hdf_cnn_file.create_dataset(dataset_name, (n_imgs, cnn_image_shape[0], cnn_image_shape[1], 3),\\\n",
    "                                      dtype=\"float32\", compression=\"gzip\")\n",
    "  ds_cnn_labels = hdf_cnn_file.create_dataset(dataset_name + \"_labels\", (n_imgs, n_classes),\\\n",
    "                                    dtype=\"int8\", compression=\"gzip\")\n",
    "  \n",
    "  n_batches = n_imgs//batch_size\n",
    "  for i in tqdm(range(n_batches)):\n",
    "    # Load data in batches\n",
    "    start_batch_index = i*batch_size\n",
    "    end_batch_index = np.min([(i+1)*batch_size, n_imgs])\n",
    "    original_batch_imgs = ds_original_imgs[start_batch_index:end_batch_index]\n",
    "    original_batch_labels = ds_original_labels[start_batch_index:end_batch_index]\n",
    "\n",
    "    cnn_batch_imgs = np.empty((batch_size, cnn_image_shape[0], cnn_image_shape[1], 3), dtype=np.float32)\n",
    "    # Labels do not need to be processed\n",
    "    cnn_batch_labels = original_batch_labels\n",
    "\n",
    "    # Preprocess all images in batch\n",
    "    for i in range(batch_size):\n",
    "      original_img = original_batch_imgs[i]\n",
    "      # De-normalization: bring back pixel values to the [0,255] range\n",
    "      non_normalized_img = np.asarray(original_img * 255, dtype=np.uint8)\n",
    "      # Scale the image to the target shape (height/width ratio is preserved due\n",
    "      # to the original and target shape values)\n",
    "      scaled_img = cv2.resize(non_normalized_img, (cnn_image_shape[1], cnn_image_shape[0]),\\\n",
    "                              interpolation=cv2.INTER_AREA)\n",
    "      # Convert grayscale image to RGB (VGG16 needs color images)\n",
    "      rgb_img = cv2.cvtColor(scaled_img, cv2.COLOR_GRAY2RGB)\n",
    "      # Normalization\n",
    "      cnn_batch_imgs[i] = rgb_img / 255\n",
    "    \n",
    "    # Write data batches\n",
    "    ds_cnn_imgs[start_batch_index:end_batch_index] = cnn_batch_imgs\n",
    "    ds_cnn_labels[start_batch_index:end_batch_index] = cnn_batch_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-9rJSEM2rEy"
   },
   "source": [
    "For each set (train. validation, test) in the original HDF5 dataset file, generate a set in a new HDF5 file to be used during the CNN training phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3p34mHNFrmoJ"
   },
   "outputs": [],
   "source": [
    "if generate_dataset:\n",
    "  with h5py.File(original_dataset_path, 'r') as hdf_original_file, h5py.File(cnn_dataset_path, 'w') as hdf_cnn_file:\n",
    "    print(\"Generating training dataset for CNN...\")\n",
    "    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"train\")\n",
    "    print(\"Generating validation dataset for CNN...\")\n",
    "    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"valid\")\n",
    "    print(\"Generating test dataset for CNN...\")\n",
    "    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QC2UQutVjQT"
   },
   "source": [
    "#Utility classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2BMHeEv_blh"
   },
   "source": [
    "##Data generator definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMmqmgWn_5-o"
   },
   "source": [
    "Class to handle large datasets (see https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly for further details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyevxtsaASWm"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, ds_imgs, ds_labels, batch_size=32, dim=(32,32,32), n_channels=3,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.ds_labels = ds_labels\n",
    "        self.ds_imgs = ds_imgs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ds_imgs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.ds_imgs.len())\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for batch_index, ds_index in enumerate(indexes):\n",
    "            # Store sample\n",
    "            X[batch_index,:] = self.ds_imgs[ds_index]\n",
    "\n",
    "            # Store class\n",
    "            y[batch_index,:] = self.ds_labels[ds_index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQNcdTDlVtDD"
   },
   "source": [
    "## History recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSL3zSahV3au"
   },
   "source": [
    "Callback class that records into a csv file the loss values and other performance measures at each training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_qEolEDV_hL"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, file_path, resume_training):\n",
    "        super(LossHistory, self).__init__()\n",
    "        self.file_path = file_path\n",
    "        self.resume_training = resume_training\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # if we are starting a new training, create the csv file and the header row\n",
    "        if not self.resume_training:\n",
    "            header = np.asarray([[\"Train-Loss\", \"Train-Accuracy\", \"Validation-Loss\", \"Validation-Accuracy\"]])\n",
    "            np.savetxt(self.file_path, header, fmt='%s', delimiter=\",\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(self.file_path, \"a\") as csv_file:\n",
    "            statistics = np.asarray([[logs.get(\"loss\"), logs.get(\"accuracy\"),\\\n",
    "                                     logs.get(\"val_loss\"), logs.get(\"val_accuracy\")]])\n",
    "            np.savetxt(csv_file, statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSGR22nLkauj"
   },
   "source": [
    "##Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9HJsv9zkcnD"
   },
   "outputs": [],
   "source": [
    "# class MulticlassTruePositives(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, name='multiclass_true_positives', **kwargs):\n",
    "#         super(MulticlassTruePositives, self).__init__(name=name, **kwargs)\n",
    "#         self.hit_per_class = self.add_weight(name='hit_per_class', shape=(1, n_classes) initializer='zeros')\n",
    "#         self.n_entries_per_class = self.add_weight(name='n_entries_per_class', shape=(1, n_classes) initializer='zeros')\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         class_index = tf.argmax(y_pred, axis=1)\n",
    "#         hit = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
    "\n",
    "#         if hit:\n",
    "#             tf.convert_to_tensor\n",
    "\n",
    "\n",
    "#         values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
    "#         values = tf.cast(values, 'float32')\n",
    "#         if sample_weight is not None:\n",
    "#             sample_weight = tf.cast(sample_weight, 'float32')\n",
    "#             values = tf.multiply(values, sample_weight)\n",
    "#         self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "#     def result(self):\n",
    "#         return self.true_positives\n",
    "\n",
    "#     def reset_states(self):\n",
    "#         # The state of the metric will be reset at the start of each epoch.\n",
    "#         self.true_positives.assign(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQSlRecCo-X_"
   },
   "source": [
    "# CNN model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjX5s9LXmHQJ"
   },
   "source": [
    "**For the following part refer to:** https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWRhKkJwHhqJ"
   },
   "source": [
    "Use the VGG16 as base model for fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWJ3xbdBn_8d"
   },
   "outputs": [],
   "source": [
    "# load VGG16, ensuring the head FC layer sets are left off, while at\n",
    "# the same time adjusting the size of the input image tensor to the\n",
    "# network\n",
    "baseModel = keras.applications.VGG16(weights=None, include_top=False,\n",
    "\tinput_tensor=Input(shape=(cnn_image_shape[0], cnn_image_shape[1], 3)), pooling=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_Po_uSwlsVm"
   },
   "source": [
    "Add the custom structure (to be trained) on top of the (trained) convolutional part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7R1mNCdOWkH"
   },
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = Dense(4096, activation=\"relu\")(headModel)\n",
    "headModel = Dense(4096, activation=\"relu\")(headModel)\n",
    "headModel = Dense(n_classes, activation=\"softmax\")(headModel)\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "cnn_model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "# for layer in baseModel.layers:\n",
    "# \tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YI-lhd-wm2EL"
   },
   "source": [
    "Compile the model basing on the configuration flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYW6Jj8GnFJ9"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005)\n",
    "\n",
    "# If we not want to train the network, load the already trained weights\n",
    "if not train_network:\n",
    "    cnn_model.load_weights(cnn_weights_path)\n",
    "# If the training process has to be resumed load the checkpointed weights\n",
    "elif resume_training:\n",
    "    cnn_model.load_weights(cnn_weights_checkpoint_path)\n",
    "\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io_NuwnWAoDm"
   },
   "source": [
    "Show model structure info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cJw8z_znAfVi",
    "outputId": "d917f402-446a-4189-8b81-95402fae26a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] summary for the whole model...\n",
      "(None, 500, 375, 3)\n",
      "(None, 16)\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 500, 375, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 500, 375, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 500, 375, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 250, 187, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 250, 187, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 250, 187, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 125, 93, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 125, 93, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 125, 93, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 125, 93, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 62, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 62, 46, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 62, 46, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 62, 46, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 31, 23, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 31, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 31, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 31, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 15, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_7 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 33,662,800\n",
      "Trainable params: 33,662,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] summary for the whole model...\")\n",
    "print(cnn_model.input_shape)\n",
    "print(cnn_model.output_shape)\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wz358JXER5p2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxLd-83MEvnJ"
   },
   "source": [
    "Save the network model into a json file and its weights in a separate HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoCE4Dn-CpY2"
   },
   "outputs": [],
   "source": [
    "def save_cnn_to_file(cnn):\n",
    "  # serialize model to JSON\n",
    "  model_json = cnn.to_json()\n",
    "  with open(cnn_model_path, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "  # serialize weights to HDF5\n",
    "  cnn.save_weights(cnn_weights_path)\n",
    "  print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpD3hX15SJNe"
   },
   "source": [
    "Train the network (if the corresponding flag is set) and save it into the Drive.\n",
    "\n",
    "Save a model checkpoint after each improvement in accuracy with respect to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "lqLwaAxQR8kb",
    "outputId": "59fb8bef-c26f-4ede-c1a5-b5569a455561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 642s 13s/step - loss: 2.7727 - accuracy: 0.0756 - val_loss: 2.7666 - val_accuracy: 0.0625\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 638s 13s/step - loss: 2.7724 - accuracy: 0.0756 - val_loss: 2.7673 - val_accuracy: 0.0625\n",
      "Epoch 3/1000\n",
      "44/50 [=========================>....] - ETA: 1:14 - loss: 2.7728 - accuracy: 0.0739"
     ]
    }
   ],
   "source": [
    "# Data generators params\n",
    "data_gen_params = {'dim': (cnn_image_shape[0], cnn_image_shape[1]),\n",
    "        'batch_size': 32,\n",
    "        'n_classes': n_classes,\n",
    "        'n_channels': 3,\n",
    "        'shuffle': True}\n",
    "\n",
    "if train_network:\n",
    "    with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(hdf_cnn_file[\"train\"], hdf_cnn_file[\"train_labels\"], **data_gen_params)\n",
    "        validation_generator = DataGenerator(hdf_cnn_file[\"valid\"], hdf_cnn_file[\"valid_labels\"], **data_gen_params)\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(cnn_weights_checkpoint_path)#, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=100, restore_best_weights=True)\n",
    "        loss_history = LossHistory(file_path=history_stats_path,resume_training=resume_training)\n",
    "\n",
    "        # Train model on dataset\n",
    "        history = cnn_model.fit_generator(generator=training_generator,\n",
    "                            validation_data=validation_generator,\n",
    "                            use_multiprocessing=True, epochs=1000,\n",
    "                            workers=0, callbacks=[es, checkpoint, loss_history], verbose=1)\n",
    "        \n",
    "        print(\"\\nTraining completed\")\n",
    "\n",
    "    save_cnn_file(cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aecu_ow1SoJq"
   },
   "source": [
    "Evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MsizQttSwU4"
   },
   "outputs": [],
   "source": [
    "with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n",
    "    # Evaluate the trained model on the test set\n",
    "    test_generator = DataGenerator(hdf_cnn_file[\"test\"], hdf_cnn_file[\"test_labels\"], **data_gen_params)\n",
    "    score = cnn_model.evaluate_generator(test_generator, verbose=1)\n",
    "\n",
    "    print(\"\\nAccuracy on test set: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGnwVN3JW8pq"
   },
   "outputs": [],
   "source": [
    "with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n",
    "    ds_imgs = hdf_cnn_file[\"test\"]\n",
    "    ds_labels = hdf_cnn_file[\"test_labels\"]\n",
    "    n_test_imgs = ds_imgs.len()\n",
    "\n",
    "    predicted_labels = cnn_model.predict(x=ds_imgs, batch_size=data_gen_params[\"batch_size\"])\n",
    "\n",
    "    ds_labels_explicit = np.argmax(ds_labels, axis=-1)\n",
    "    predicted_labels_explicit = np.argmax(predicted_labels, axis=-1)\n",
    "    print(ds_labels_explicit.shape)\n",
    "    print(predicted_labels_explicit.shape)\n",
    "    comparison_matrix = np.empty((ds_labels.shape[0], 2), dtype=np.int32)\n",
    "    comparison_matrix[:,0] = predicted_labels_explicit\n",
    "    comparison_matrix[:,1] = ds_labels_explicit\n",
    "    print(comparison_matrix.shape)\n",
    "    print(comparison_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DCaRLIXUrqAE",
    "C2BMHeEv_blh"
   ],
   "name": "Document Classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
