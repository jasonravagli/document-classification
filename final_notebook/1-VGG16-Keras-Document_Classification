{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1-VGG16-Keras-Document_Classification","provenance":[],"collapsed_sections":["CQNcdTDlVtDD","XSGR22nLkauj"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IlvMFbA9eaHL","colab_type":"text"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"ozb1pju5no1E","colab_type":"text"},"source":["Install required packages:"]},{"cell_type":"code","metadata":{"id":"W4kfsWBdnvFE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EF8nO8tCn0rV","colab_type":"text"},"source":["Import required packages:"]},{"cell_type":"code","metadata":{"id":"v7lulcZCn3Ph","colab_type":"code","colab":{}},"source":["import h5py\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","import keras.backend as K\n","from keras.applications import VGG16\n","from keras.layers.core import Dropout\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","import cv2\n","from tqdm import tqdm\n","\n","# Google Drive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth, drive\n","from oauth2client.client import GoogleCredentials\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTxETaJrkADl","colab_type":"text"},"source":["Authenticate to Google Drive to access dataset folder:"]},{"cell_type":"code","metadata":{"id":"5U4qYrxteh7r","colab_type":"code","outputId":"d1e4e050-8993-43f7-8121-efee4eee1f10","executionInfo":{"status":"ok","timestamp":1588161779120,"user_tz":-120,"elapsed":2194,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","GoogleDrive(gauth)\n","drive.mount(\"/content/drive\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dUJh9_GWocEn","colab_type":"text"},"source":["General parameters and settings:"]},{"cell_type":"code","metadata":{"id":"GF6nkn_poed2","colab_type":"code","colab":{}},"source":["original_dataset_path = \"/content/drive/My Drive/document-classification/datasets/rvl-cdip/mini-dataset-1600-200-200.h5\"\n","cnn_dataset_path = \"/content/drive/My Drive/document-classification/datasets/rvl-cdip/cnn-mini-dataset-1600-200-200.h5\"\n","cnn_model_path = \"/content/drive/My Drive/document-classification/models/model.json\"\n","cnn_weights_path = \"/content/drive/My Drive/document-classification/models/weights.h5\"\n","cnn_weights_checkpoint_path = \"/content/drive/My Drive/document-classification/checkpoints/checkpoint_weights.h5\"\n","history_stats_path = \"/content/drive/My Drive/document-classification/history/history_stats.csv\"\n","\n","# Flag to generate CNN dataset (set it to False if the dataset has already been generated)\n","generate_dataset = False\n","# False: skip training process and load the already learned weights to only evaluate the network\n","train_network = True\n","# True: resume the training from a checkpoint; False: start a new training\n","# This flag is checked only if train_network=True\n","resume_training = False\n","\n","# Shape of the images read from the mini-dataset\n","original_img_shape = (1000, 750)\n","# Shape of the images in input to the CNN\n","cnn_image_shape = (500, 375)\n","# Number of images classes\n","n_classes = 16"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"om7sJs4B0Ji0","colab_type":"text"},"source":["Check if GPU is available:"]},{"cell_type":"code","metadata":{"id":"h5zS1kXepHTe","colab_type":"code","outputId":"267e9fbe-ed06-41ec-e366-5cd8928a2ba2","executionInfo":{"status":"ok","timestamp":1588161779122,"user_tz":-120,"elapsed":2178,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["from tensorflow.python.client import device_lib \n","display(device_lib.list_local_devices())\n","assert tf.config.list_physical_devices('GPU')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 2374516325475957232, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 10980962414237043798\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 16557583352204871327\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15701463552\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 3608321545066985797\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DCaRLIXUrqAE","colab_type":"text"},"source":["# Dataset preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"_w8surVL386H","colab_type":"text"},"source":["**Function to generate a dataset for the CNN (VGG16) starting from the corresponding original dataset.**\n","\n","It reads all images from the original dataset, preprocesses them according to the CNN requirements (resize, convert to RGB) and finally saves them into the new dataset."]},{"cell_type":"code","metadata":{"id":"CFyJE8oQ4E0a","colab_type":"code","colab":{}},"source":["def generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, dataset_name):\n","  # Number of data rows to read from original file, process and write to the CNN file at the same time\n","  # (To speedup read/write operations)\n","  batch_size = 64\n","\n","  # Read datasets from the original HDF5 file\n","  ds_original_imgs = hdf_original_file[dataset_name]\n","  ds_original_labels = hdf_original_file[dataset_name + \"_labels\"]\n","\n","  n_imgs = ds_original_imgs.len()\n","\n","  # Create omonymous datasets into the HDF5 file for the CNN\n","  ds_cnn_imgs = hdf_cnn_file.create_dataset(dataset_name, (n_imgs, cnn_image_shape[0], cnn_image_shape[1], 3),\\\n","                                      dtype=\"float32\", compression=\"gzip\")\n","  ds_cnn_labels = hdf_cnn_file.create_dataset(dataset_name + \"_labels\", (n_imgs, n_classes),\\\n","                                    dtype=\"int8\", compression=\"gzip\")\n","  \n","  n_batches = n_imgs//batch_size\n","  for i in tqdm(range(n_batches)):\n","    # Load data in batches\n","    start_batch_index = i*batch_size\n","    end_batch_index = np.min([(i+1)*batch_size, n_imgs])\n","    original_batch_imgs = ds_original_imgs[start_batch_index:end_batch_index]\n","    original_batch_labels = ds_original_labels[start_batch_index:end_batch_index]\n","\n","    cnn_batch_imgs = np.empty((batch_size, cnn_image_shape[0], cnn_image_shape[1], 3), dtype=np.float32)\n","    # Labels do not need to be processed\n","    cnn_batch_labels = original_batch_labels\n","\n","    # Preprocess all images in batch\n","    for j in range(batch_size):\n","      original_img = original_batch_imgs[j]\n","      # De-normalization: bring back pixel values to the [0,255] range\n","      non_normalized_img = np.asarray(original_img * 255, dtype=np.uint8)\n","      # Scale the image to the target shape (height/width ratio is preserved due\n","      # to the original and target shape values)\n","      scaled_img = cv2.resize(non_normalized_img, (cnn_image_shape[1], cnn_image_shape[0]),\\\n","                              interpolation=cv2.INTER_AREA)\n","      # Convert grayscale image to RGB (VGG16 needs color images)\n","      rgb_img = cv2.cvtColor(scaled_img, cv2.COLOR_GRAY2RGB)\n","      # Normalization\n","      cnn_batch_imgs[j] = rgb_img / 255\n","    \n","    # Write data batches\n","    ds_cnn_imgs[start_batch_index:end_batch_index] = cnn_batch_imgs\n","    ds_cnn_labels[start_batch_index:end_batch_index] = cnn_batch_labels\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-9rJSEM2rEy","colab_type":"text"},"source":["For each set (train. validation, test) in the original HDF5 dataset file, generate a set in a new HDF5 file to be used during the CNN training phase:"]},{"cell_type":"code","metadata":{"id":"3p34mHNFrmoJ","colab_type":"code","colab":{}},"source":["if generate_dataset:\n","  with h5py.File(original_dataset_path, 'r') as hdf_original_file, h5py.File(cnn_dataset_path, 'w') as hdf_cnn_file:\n","    print(\"Generating training dataset for CNN...\")\n","    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"train\")\n","    print(\"Generating validation dataset for CNN...\")\n","    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"valid\")\n","    print(\"Generating test dataset for CNN...\")\n","    generate_dataset_for_cnn(hdf_original_file, hdf_cnn_file, \"test\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QC2UQutVjQT","colab_type":"text"},"source":["#Utility classes"]},{"cell_type":"markdown","metadata":{"id":"C2BMHeEv_blh","colab_type":"text"},"source":["##Data generator definition"]},{"cell_type":"markdown","metadata":{"id":"uMmqmgWn_5-o","colab_type":"text"},"source":["Class to handle large datasets (see https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly for further details)"]},{"cell_type":"code","metadata":{"id":"uyevxtsaASWm","colab_type":"code","colab":{}},"source":["class DataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, ds_imgs, ds_labels, batch_size=32, dim=(32,32,32), n_channels=3,\n","                 n_classes=10, shuffle=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.ds_labels = ds_labels\n","        self.ds_imgs = ds_imgs\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.ds_imgs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Generate data\n","        X, y = self.__data_generation(indexes)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(self.ds_imgs.len())\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, indexes):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n","        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n","\n","        # Generate data\n","        for batch_index, ds_index in enumerate(indexes):\n","            # Store sample\n","            X[batch_index,:] = self.ds_imgs[ds_index]\n","\n","            # Store class\n","            y[batch_index,:] = self.ds_labels[ds_index]\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQNcdTDlVtDD","colab_type":"text"},"source":["## History recording"]},{"cell_type":"markdown","metadata":{"id":"xSL3zSahV3au","colab_type":"text"},"source":["Callback class that records into a csv file the loss values and other performance measures at each training epoch"]},{"cell_type":"code","metadata":{"id":"T_qEolEDV_hL","colab_type":"code","colab":{}},"source":["class LossHistory(keras.callbacks.Callback):\n","    def __init__(self, file_path, resume_training):\n","        super(LossHistory, self).__init__()\n","        self.file_path = file_path\n","        self.resume_training = resume_training\n","\n","\n","    def on_train_begin(self, logs={}):\n","        # if we are starting a new training, create the csv file and the header row\n","        if not self.resume_training:\n","            header = np.asarray([[\"Train-Loss\", \"Train-Accuracy\", \"Validation-Loss\", \"Validation-Accuracy\"]])\n","            np.savetxt(self.file_path, header, fmt='%s', delimiter=\",\")\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        with open(self.file_path, \"a\") as csv_file:\n","            statistics = np.asarray([[logs.get(\"loss\"), logs.get(\"accuracy\"),\\\n","                                     logs.get(\"val_loss\"), logs.get(\"val_accuracy\")]])\n","            np.savetxt(csv_file, statistics)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSGR22nLkauj","colab_type":"text"},"source":["##Custom metrics"]},{"cell_type":"code","metadata":{"id":"Y9HJsv9zkcnD","colab_type":"code","colab":{}},"source":["# class MulticlassTruePositives(tf.keras.metrics.Metric):\n","#     def __init__(self, name='multiclass_true_positives', **kwargs):\n","#         super(MulticlassTruePositives, self).__init__(name=name, **kwargs)\n","#         self.hit_per_class = self.add_weight(name='hit_per_class', shape=(1, n_classes) initializer='zeros')\n","#         self.n_entries_per_class = self.add_weight(name='n_entries_per_class', shape=(1, n_classes) initializer='zeros')\n","\n","#     def update_state(self, y_true, y_pred, sample_weight=None):\n","#         class_index = tf.argmax(y_pred, axis=1)\n","#         hit = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n","\n","#         if hit:\n","#             tf.convert_to_tensor\n","\n","\n","#         values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n","#         values = tf.cast(values, 'float32')\n","#         if sample_weight is not None:\n","#             sample_weight = tf.cast(sample_weight, 'float32')\n","#             values = tf.multiply(values, sample_weight)\n","#         self.true_positives.assign_add(tf.reduce_sum(values))\n","\n","#     def result(self):\n","#         return self.true_positives\n","\n","#     def reset_states(self):\n","#         # The state of the metric will be reset at the start of each epoch.\n","#         self.true_positives.assign(0.)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vQSlRecCo-X_","colab_type":"text"},"source":["# CNN model definition"]},{"cell_type":"markdown","metadata":{"id":"XjX5s9LXmHQJ","colab_type":"text"},"source":["**For the following part refer to:** https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/"]},{"cell_type":"markdown","metadata":{"id":"GWRhKkJwHhqJ","colab_type":"text"},"source":["Use the VGG16 as base model for fine-tuning:"]},{"cell_type":"code","metadata":{"id":"UWJ3xbdBn_8d","colab_type":"code","outputId":"002b24cf-0bf1-4c29-96f3-7e49c25c50bb","executionInfo":{"status":"ok","timestamp":1588161785740,"user_tz":-120,"elapsed":8731,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# load VGG16, ensuring the head FC layer sets are left off, while at\n","# the same time adjusting the size of the input image tensor to the\n","# network\n","baseModel = keras.applications.VGG16(weights=\"imagenet\", include_top=False,\n","\tinput_tensor=Input(shape=(cnn_image_shape[0], cnn_image_shape[1], 3)), pooling=\"max\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 5s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b_Po_uSwlsVm","colab_type":"text"},"source":["Add the custom structure (to be trained) on top of the (trained) convolutional part:"]},{"cell_type":"code","metadata":{"id":"n7R1mNCdOWkH","colab_type":"code","colab":{}},"source":["# construct the head of the model that will be placed on top of the\n","# the base model\n","headModel = baseModel.output\n","headModel = Dense(4096, activation=\"relu\")(headModel)\n","headModel = Dense(4096, activation=\"relu\")(headModel)\n","headModel = Dense(n_classes, activation=\"relu\")(headModel)\n","headModel = Dense(n_classes, activation=\"softmax\")(headModel)\n","# place the head FC model on top of the base model (this will become\n","# the actual model we will train)\n","cnn_model = Model(inputs=baseModel.input, outputs=headModel)\n","# loop over all layers in the base model and freeze them so they will\n","# *not* be updated during the first training process\n","for layer in baseModel.layers:\n","\tlayer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YI-lhd-wm2EL","colab_type":"text"},"source":["Compile the model basing on the configuration flags:"]},{"cell_type":"code","metadata":{"id":"XYW6Jj8GnFJ9","colab_type":"code","colab":{}},"source":["opt = Adam(lr=0.0001)\n","\n","# If we not want to train the network, load the already trained weights\n","if not train_network:\n","    cnn_model.load_weights(cnn_weights_path)\n","# If the training process has to be resumed load the checkpointed weights\n","elif resume_training:\n","    cnn_model.load_weights(cnn_weights_checkpoint_path)\n","\n","cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Io_NuwnWAoDm","colab_type":"text"},"source":["Show model structure info:"]},{"cell_type":"code","metadata":{"id":"cJw8z_znAfVi","colab_type":"code","outputId":"6a2987b3-4700-4575-d3eb-c8468dd88c65","executionInfo":{"status":"ok","timestamp":1588161785742,"user_tz":-120,"elapsed":8693,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"[INFO] summary for the whole model...\")\n","print(cnn_model.input_shape)\n","print(cnn_model.output_shape)\n","print(cnn_model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] summary for the whole model...\n","(None, 500, 375, 3)\n","(None, 16)\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 500, 375, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 500, 375, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 500, 375, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 250, 187, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 250, 187, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 250, 187, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 125, 93, 128)      0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 125, 93, 256)      295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 125, 93, 256)      590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 125, 93, 256)      590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 62, 46, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 62, 46, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 62, 46, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 62, 46, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 31, 23, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 31, 23, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 31, 23, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 31, 23, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 15, 11, 512)       0         \n","_________________________________________________________________\n","global_max_pooling2d_2 (Glob (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4096)              2101248   \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 16)                65552     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 16)                272       \n","=================================================================\n","Total params: 33,663,072\n","Trainable params: 18,948,384\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wz358JXER5p2","colab_type":"text"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"JxLd-83MEvnJ","colab_type":"text"},"source":["Save the network model into a json file and its weights in a separate HDF5 file:"]},{"cell_type":"code","metadata":{"id":"FoCE4Dn-CpY2","colab_type":"code","colab":{}},"source":["def save_cnn_to_file(cnn):\n","  # serialize model to JSON\n","  model_json = cnn.to_json()\n","  with open(cnn_model_path, 'w') as json_file:\n","    json_file.write(model_json)\n","  # serialize weights to HDF5\n","  cnn.save_weights(cnn_weights_path)\n","  print(\"Model saved\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mpD3hX15SJNe","colab_type":"text"},"source":["Train the network (if the corresponding flag is set) and save it into the Drive.\n","\n","Save a model checkpoint after each improvement in accuracy with respect to the validation set."]},{"cell_type":"code","metadata":{"id":"lqLwaAxQR8kb","colab_type":"code","outputId":"09a21275-70d5-43af-b189-888d8c7d713b","executionInfo":{"status":"error","timestamp":1588177830560,"user_tz":-120,"elapsed":12328945,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Data generators params\n","data_gen_params = {'dim': (cnn_image_shape[0], cnn_image_shape[1]),\n","        'batch_size': 32,\n","        'n_classes': n_classes,\n","        'n_channels': 3,\n","        'shuffle': True}\n","\n","if train_network:\n","    with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n","        # Generators\n","        training_generator = DataGenerator(hdf_cnn_file[\"train\"], hdf_cnn_file[\"train_labels\"], **data_gen_params)\n","        validation_generator = DataGenerator(hdf_cnn_file[\"valid\"], hdf_cnn_file[\"valid_labels\"], **data_gen_params)\n","        \n","        checkpoint = ModelCheckpoint(cnn_weights_checkpoint_path)#, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True)\n","        es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=100, restore_best_weights=True)\n","        loss_history = LossHistory(file_path=history_stats_path,resume_training=resume_training)\n","\n","        # Train model on dataset\n","        history = cnn_model.fit_generator(generator=training_generator,\n","                            validation_data=validation_generator,\n","                            use_multiprocessing=True, epochs=1000,\n","                            workers=0, callbacks=[es, checkpoint, loss_history], verbose=1)\n","        \n","        print(\"\\nTraining completed\")\n","\n","    save_cnn_file(cnn_model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","50/50 [==============================] - 388s 8s/step - loss: 2.7399 - accuracy: 0.0700 - val_loss: 2.7448 - val_accuracy: 0.0990\n","Epoch 2/1000\n","50/50 [==============================] - 388s 8s/step - loss: 2.6991 - accuracy: 0.1006 - val_loss: 2.6941 - val_accuracy: 0.1198\n","Epoch 3/1000\n","50/50 [==============================] - 386s 8s/step - loss: 2.6172 - accuracy: 0.1225 - val_loss: 2.6466 - val_accuracy: 0.0885\n","Epoch 4/1000\n","50/50 [==============================] - 386s 8s/step - loss: 2.5949 - accuracy: 0.1206 - val_loss: 2.7287 - val_accuracy: 0.1042\n","Epoch 5/1000\n","50/50 [==============================] - 387s 8s/step - loss: 2.5705 - accuracy: 0.1244 - val_loss: 2.5791 - val_accuracy: 0.1458\n","Epoch 6/1000\n","50/50 [==============================] - 386s 8s/step - loss: 2.5061 - accuracy: 0.1625 - val_loss: 2.6213 - val_accuracy: 0.1719\n","Epoch 7/1000\n","50/50 [==============================] - 384s 8s/step - loss: 2.4658 - accuracy: 0.1538 - val_loss: 2.6124 - val_accuracy: 0.1562\n","Epoch 8/1000\n","50/50 [==============================] - 384s 8s/step - loss: 2.4333 - accuracy: 0.1556 - val_loss: 2.5957 - val_accuracy: 0.1719\n","Epoch 9/1000\n","50/50 [==============================] - 384s 8s/step - loss: 2.3760 - accuracy: 0.1675 - val_loss: 2.6048 - val_accuracy: 0.1615\n","Epoch 10/1000\n","50/50 [==============================] - 383s 8s/step - loss: 2.3207 - accuracy: 0.1756 - val_loss: 2.6526 - val_accuracy: 0.1875\n","Epoch 11/1000\n","50/50 [==============================] - 382s 8s/step - loss: 2.2899 - accuracy: 0.2175 - val_loss: 2.7048 - val_accuracy: 0.2031\n","Epoch 12/1000\n","50/50 [==============================] - 382s 8s/step - loss: 2.2314 - accuracy: 0.2438 - val_loss: 2.5044 - val_accuracy: 0.2135\n","Epoch 13/1000\n","50/50 [==============================] - 380s 8s/step - loss: 2.1463 - accuracy: 0.2594 - val_loss: 2.5642 - val_accuracy: 0.2292\n","Epoch 14/1000\n","50/50 [==============================] - 380s 8s/step - loss: 2.1266 - accuracy: 0.2675 - val_loss: 2.5974 - val_accuracy: 0.2292\n","Epoch 15/1000\n","50/50 [==============================] - 380s 8s/step - loss: 2.0515 - accuracy: 0.2738 - val_loss: 2.4648 - val_accuracy: 0.2292\n","Epoch 16/1000\n","50/50 [==============================] - 382s 8s/step - loss: 2.0189 - accuracy: 0.2812 - val_loss: 2.5685 - val_accuracy: 0.2500\n","Epoch 17/1000\n","50/50 [==============================] - 381s 8s/step - loss: 1.9690 - accuracy: 0.2912 - val_loss: 2.7288 - val_accuracy: 0.2396\n","Epoch 18/1000\n","50/50 [==============================] - 381s 8s/step - loss: 1.8835 - accuracy: 0.3375 - val_loss: 2.5392 - val_accuracy: 0.3385\n","Epoch 19/1000\n","50/50 [==============================] - 379s 8s/step - loss: 1.8138 - accuracy: 0.3850 - val_loss: 2.5074 - val_accuracy: 0.3490\n","Epoch 20/1000\n","50/50 [==============================] - 378s 8s/step - loss: 1.7335 - accuracy: 0.4156 - val_loss: 2.4964 - val_accuracy: 0.3646\n","Epoch 21/1000\n","50/50 [==============================] - 382s 8s/step - loss: 1.6205 - accuracy: 0.4544 - val_loss: 2.5687 - val_accuracy: 0.3802\n","Epoch 22/1000\n","50/50 [==============================] - 380s 8s/step - loss: 1.5477 - accuracy: 0.4850 - val_loss: 2.5136 - val_accuracy: 0.4010\n","Epoch 23/1000\n","50/50 [==============================] - 381s 8s/step - loss: 1.4931 - accuracy: 0.4938 - val_loss: 2.4734 - val_accuracy: 0.3958\n","Epoch 24/1000\n","50/50 [==============================] - 382s 8s/step - loss: 1.4015 - accuracy: 0.5269 - val_loss: 2.3590 - val_accuracy: 0.4375\n","Epoch 25/1000\n","50/50 [==============================] - 382s 8s/step - loss: 1.3536 - accuracy: 0.5425 - val_loss: 2.3582 - val_accuracy: 0.4115\n","Epoch 26/1000\n","50/50 [==============================] - 383s 8s/step - loss: 1.3137 - accuracy: 0.5688 - val_loss: 2.2734 - val_accuracy: 0.3802\n","Epoch 27/1000\n","50/50 [==============================] - 384s 8s/step - loss: 1.2313 - accuracy: 0.5950 - val_loss: 2.5101 - val_accuracy: 0.4219\n","Epoch 28/1000\n","50/50 [==============================] - 383s 8s/step - loss: 1.1572 - accuracy: 0.6125 - val_loss: 2.7500 - val_accuracy: 0.4271\n","Epoch 29/1000\n","50/50 [==============================] - 383s 8s/step - loss: 1.0852 - accuracy: 0.6488 - val_loss: 2.4474 - val_accuracy: 0.3698\n","Epoch 30/1000\n","50/50 [==============================] - 385s 8s/step - loss: 1.0299 - accuracy: 0.6806 - val_loss: 2.3384 - val_accuracy: 0.4167\n","Epoch 31/1000\n","50/50 [==============================] - 386s 8s/step - loss: 0.9788 - accuracy: 0.7169 - val_loss: 2.6208 - val_accuracy: 0.4583\n","Epoch 32/1000\n","50/50 [==============================] - 382s 8s/step - loss: 0.9344 - accuracy: 0.7462 - val_loss: 2.7223 - val_accuracy: 0.5000\n","Epoch 33/1000\n","50/50 [==============================] - 383s 8s/step - loss: 0.8880 - accuracy: 0.7619 - val_loss: 2.7081 - val_accuracy: 0.4115\n","Epoch 34/1000\n","50/50 [==============================] - 382s 8s/step - loss: 0.8411 - accuracy: 0.7625 - val_loss: 2.4638 - val_accuracy: 0.4740\n","Epoch 35/1000\n","50/50 [==============================] - 393s 8s/step - loss: 0.7835 - accuracy: 0.7981 - val_loss: 2.8193 - val_accuracy: 0.4583\n","Epoch 36/1000\n","50/50 [==============================] - 389s 8s/step - loss: 0.7256 - accuracy: 0.8062 - val_loss: 2.6877 - val_accuracy: 0.4792\n","Epoch 37/1000\n","50/50 [==============================] - 387s 8s/step - loss: 0.6970 - accuracy: 0.8306 - val_loss: 2.6900 - val_accuracy: 0.4740\n","Epoch 38/1000\n","50/50 [==============================] - 387s 8s/step - loss: 0.6916 - accuracy: 0.8306 - val_loss: 3.5417 - val_accuracy: 0.4115\n","Epoch 39/1000\n","50/50 [==============================] - 380s 8s/step - loss: 0.6222 - accuracy: 0.8469 - val_loss: 2.8404 - val_accuracy: 0.4740\n","Epoch 40/1000\n","50/50 [==============================] - 382s 8s/step - loss: 0.5772 - accuracy: 0.8625 - val_loss: 3.3390 - val_accuracy: 0.4271\n","Epoch 41/1000\n","50/50 [==============================] - 387s 8s/step - loss: 0.5150 - accuracy: 0.8781 - val_loss: 3.2597 - val_accuracy: 0.4635\n","Epoch 42/1000\n","26/50 [==============>...............] - ETA: 3:00 - loss: 0.4986 - accuracy: 0.8906"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-95c62343de28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             workers=0, callbacks=[es, checkpoint, loss_history], verbose=1)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36miter_sequence_infinite\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-e1e3bb6e4189>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-e1e3bb6e4189>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, indexes)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Store sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Store class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"aecu_ow1SoJq","colab_type":"text"},"source":["Evaluate the model on the test set:"]},{"cell_type":"code","metadata":{"id":"0MsizQttSwU4","colab_type":"code","outputId":"fbb72cf6-d7f1-4424-833c-355f79bdc126","executionInfo":{"status":"ok","timestamp":1588177853897,"user_tz":-120,"elapsed":12668,"user":{"displayName":"JASON RAVAGLI","photoUrl":"","userId":"01884994422007125599"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n","    # Evaluate the trained model on the test set\n","    test_generator = DataGenerator(hdf_cnn_file[\"test\"], hdf_cnn_file[\"test_labels\"], **data_gen_params)\n","    score = cnn_model.evaluate_generator(test_generator, verbose=1)\n","\n","    print(\"\\nAccuracy on test set: \" + str(score))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6/6 [==============================] - 11s 2s/step\n","\n","Accuracy on test set: [2.622559070587158, 0.4322916567325592]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gGnwVN3JW8pq","colab_type":"code","colab":{}},"source":["with h5py.File(cnn_dataset_path, 'r') as hdf_cnn_file:\n","    ds_imgs = hdf_cnn_file[\"test\"]\n","    ds_labels = hdf_cnn_file[\"test_labels\"]\n","    n_test_imgs = ds_imgs.len()\n","\n","    predicted_labels = cnn_model.predict(x=ds_imgs, batch_size=data_gen_params[\"batch_size\"])\n","\n","    ds_labels_explicit = np.argmax(ds_labels, axis=-1)\n","    predicted_labels_explicit = np.argmax(predicted_labels, axis=-1)\n","    print(ds_labels_explicit.shape)\n","    print(predicted_labels_explicit.shape)\n","    comparison_matrix = np.empty((ds_labels.shape[0], 2), dtype=np.int32)\n","    comparison_matrix[:,0] = predicted_labels_explicit\n","    comparison_matrix[:,1] = ds_labels_explicit\n","    print(comparison_matrix.shape)\n","    print(comparison_matrix)\n"],"execution_count":0,"outputs":[]}]}